{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание многопоточных приложений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной лекции мы посмотрим как работать с многопоточностью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключаем нужные библиотеки\n",
    "import multiprocessing \n",
    "import threading\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pymorphy2\n",
    "\n",
    "import queue\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте просто попробуем запустить два потока, которые будут выводить каждый свое значение.\n",
    "\n",
    "Для создания потока используется `threading.Thread`, в параметр `target` передается функция, которая будет выполняться в этом потоке. Для того, чтобы поток начал выполняться, необходимо вызвать функцию `start`. Если необходимо дождаться окончания выполнения потока, вызывается функция `join`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func 1 says  1\n",
      "Func 2 says  2\n",
      "I can fly!\n",
      "Func 1 says  101\n",
      "Func 2 says  202\n",
      "Func 1 says  201\n",
      "Func 1 says  301\n",
      "Func 2 says  402\n",
      "Func 1 says  401\n",
      "Func 2 says  602\n",
      "Func 1 says  501\n",
      "Func 1 says  601\n",
      "Func 2 says  802\n",
      "Func 1 says  701\n",
      "Func 1 says  801\n",
      "Func 2 says  1002\n",
      "Func 1 says  901\n",
      "Func 2 says  1202\n",
      "Process 1 is finished\n",
      "Func 2 says  1402\n",
      "Func 2 says  1602\n",
      "Func 2 says  1802\n",
      "The work is done\n",
      "Time estimated  8.260782480239868\n"
     ]
    }
   ],
   "source": [
    "def func1():\n",
    "    var1 = 0\n",
    "    for i in range(1000):\n",
    "        var1 += 1\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Func 1 says \", var1)\n",
    "        time.sleep(random.random()/100) # засыпаем на случайный промежуток времени.\n",
    "            \n",
    "def func2():\n",
    "    var2 = 0\n",
    "    for i in range(1000):\n",
    "        var2 += 2\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Func 2 says \", var2)\n",
    "        time.sleep(random.random()/100+0.003) # засыпаем на случайный промежуток времени.\n",
    "            \n",
    "t1 = time.time()\n",
    "\n",
    "# создаем, а потом запускаем потоки.\n",
    "pr1=threading.Thread(target=func1)\n",
    "pr2=threading.Thread(target=func2)\n",
    "pr1.start()\n",
    "pr2.start()\n",
    "print(\"I can fly!\")\n",
    "\n",
    "pr1.join()\n",
    "print(\"Process 1 is finished\")\n",
    "pr2.join()\n",
    "print(\"The work is done\")\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Time estimated \", t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для создания процесса используется `multiprocessing.Process`, принимающий в параметр `target` функцию, которая будет выполняться в этом потоке. Для того, чтобы процесс начал выполняться, необходимо вызвать функцию `start`. Если необходимо дождаться окончания выполнения потока, вызывается функция `join`. Если процесс не будет переходить в режим ожидания, он выполнится от начала и до конца при вызове функции `start`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func 1 says  1\n",
      "Func 2 says  2\n",
      "I can fly!\n",
      "Func 1 says  101\n",
      "Func 2 says  202\n",
      "Func 1 says  201\n",
      "Func 1 says  301\n",
      "Func 2 says  402\n",
      "Func 1 says  401\n",
      "Func 2 says  602\n",
      "Func 1 says  501\n",
      "Func 1 says  601\n",
      "Func 2 says  802\n",
      "Func 1 says  701\n",
      "Func 2 says  1002\n",
      "Func 1 says  801\n",
      "Func 1 says  901\n",
      "Func 2 says  1202\n",
      "Process 1 is finished\n",
      "Func 2 says  1402\n",
      "Func 2 says  1602\n",
      "Func 2 says  1802\n",
      "The work is done\n",
      "Time estimated  8.296901941299438\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "# создаем, а потом запускаем потоки.\n",
    "pr1=multiprocessing.Process(target=func1)\n",
    "pr2=multiprocessing.Process(target=func2)\n",
    "pr1.start()\n",
    "pr2.start()\n",
    "print(\"I can fly!\")\n",
    "\n",
    "pr1.join()\n",
    "print(\"Process 1 is finished\")\n",
    "pr2.join()\n",
    "print(\"The work is done\")\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Time estimated \", t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем сделать тоже самое, но для одной и той же переменной - две функции будут увеличивать значение одной переменной по очереди."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func 1 says  1\n",
      "Func 2 says  2\n",
      "Func 1 says  101\n",
      "Func 2 says  202\n",
      "Func 1 says  201\n",
      "Func 2 says  402\n",
      "Func 1 says  301\n",
      "Func 2 says  602\n",
      "Func 1 says  401\n",
      "Func 2 says  802\n",
      "Func 1 says  501\n",
      "Func 2 says  1002\n",
      "Func 1 says  601\n",
      "Func 2 says  1202\n",
      "Func 1 says  701\n",
      "Func 2 says  1402\n",
      "Func 1 says  801\n",
      "Func 2 says  1602\n",
      "Func 1 says  901\n",
      "Func 2 says  1802\n",
      "Time estimated 5.247998952865601\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "Loki = 0\n",
    "\n",
    "def func1():\n",
    "    global Loki\n",
    "    for i in range(1000):\n",
    "        Loki += 1\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Func 1 says \", Loki)\n",
    "        time.sleep(random.random()/100) # засыпаем на случайный промежуток времени.\n",
    "            \n",
    "def func2():\n",
    "    global Loki\n",
    "    for i in range(1000):\n",
    "        Loki += 2\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Func 2 says \", Loki)\n",
    "        time.sleep(random.random()/100) # засыпаем на случайный промежуток времени.\n",
    "            \n",
    "# создаем, а потом запускаем потоки.\n",
    "pr1=multiprocessing.Process(target=func1)\n",
    "pr2=multiprocessing.Process(target=func2)\n",
    "pr1.start()\n",
    "pr2.start()\n",
    "\n",
    "pr1.join()\n",
    "pr2.join()\n",
    "t2 = time.time()\n",
    "print(\"Time estimated\", t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выглядит так, как будто каждый процесс работает со своей собственной переменной. Да, это так, это ведь независимые процессы, они выполняются каждый на своей копии GIL и комплекте переменных.\n",
    "\n",
    "Теперь попытаемся сделать всё тоже самое, но на потоках, выполняющихся в рамках одного процесса, но в разных потоках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func 1 says  1\n",
      "Func 2 says  3\n",
      "Func 1 says  269\n",
      "Func 2 says  323\n",
      "Func 1 says  537\n",
      "Func 2 says  639\n",
      "Func 1 says  815\n",
      "Func 2 says  939\n",
      "Func 1 says  1135\n",
      "Func 2 says  1239\n",
      "Func 1 says  1439\n",
      "Func 2 says  1535\n",
      "Func 1 says  1755\n",
      "Func 2 says  1832\n",
      "Func 1 says  2039\n",
      "Func 2 says  2137\n",
      "Func 1 says  2341\n",
      "Func 2 says  2433\n",
      "Func 1 says  2639\n",
      "Func 2 says  2737\n",
      "Time estimated  5.2792394161224365\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "Loki = 0\n",
    "\n",
    "def func1():\n",
    "    global Loki\n",
    "    for i in range(1000):\n",
    "        Loki += 1\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Func 1 says \", Loki)\n",
    "        time.sleep(random.random()/100) # засыпаем на случайный промежуток времени.\n",
    "            \n",
    "def func2():\n",
    "    global Loki\n",
    "    for i in range(1000):\n",
    "        Loki += 2\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Func 2 says \", Loki)\n",
    "        time.sleep(random.random()/100) # засыпаем на случайный промежуток времени.\n",
    "            \n",
    "# создаем, а потом запускаем потоки.\n",
    "pr1=threading.Thread(target=func1)\n",
    "pr2=threading.Thread(target=func2)\n",
    "pr1.start()\n",
    "pr2.start()\n",
    "\n",
    "pr1.join()\n",
    "pr2.join()\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Time estimated \", t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда-то давно, такой код обязательно вызвал бы исключительную ситуацию. Но сейчас GIL ам блокирует нужные переменные, не позволяя разным процессам обращаться к ним одновременно. В итоге всё работает именно так, как хотелось бы.\n",
    "\n",
    "Помимо этого, обратите внимание, что время выполнения в обоих случаях примерно одинаково. Еще в Python 3.6 потоки работали не параллельно, а последовательно внутри одного и того же потока, а переключение осуществлялось не средствами ОС, а самого GIL. Как следствие, применение таких потоков не ускоряло работу программы. При этом процессы работали действительно параллельно. Сейчас потоки в самом деле выполняются параллельно, да и запускаются гораздо быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При помощи объекта типа `Lock` можно блокировать выполнение критических фрагментов кода. Например, если мы пишем в файл в нескольких потоках, мы должны гарантировать, что мы запишем свой фрагмент данных от начала и до конца. При этом другой поток не прервет наш вывод и не выедет свою информацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func 1 says  1\n",
      "Func 2 says  2\n",
      "Func 2 says  197\n",
      "Func 1 says  207\n",
      "Func 2 says  389\n",
      "Func 1 says  416\n",
      "Func 2 says  582\n",
      "Func 1 says  617\n",
      "Func 2 says  781\n",
      "Func 1 says  819\n",
      "Func 2 says  980\n",
      "Func 1 says  1030\n",
      "Func 2 says  1166\n",
      "Func 1 says  1235\n",
      "Func 2 says  1363\n",
      "Func 1 says  1442\n",
      "Func 2 says  1568\n",
      "Func 1 says  1635\n",
      "Func 2 says  1778\n",
      "Func 1 says  1831\n"
     ]
    }
   ],
   "source": [
    "lk = threading.Lock()\n",
    "\n",
    "Loki = 0\n",
    "\n",
    "def func1():\n",
    "    global Loki\n",
    "    for i in range(1000):\n",
    "        lk.acquire()\n",
    "        Loki += 1\n",
    "        lk.release()\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Func 1 says \", Loki)\n",
    "        time.sleep(random.random()/100) # засыпаем на случайный промежуток времени.\n",
    "            \n",
    "def func2():\n",
    "    global Loki\n",
    "    for i in range(1000):\n",
    "        lk.acquire()\n",
    "        Loki += 1\n",
    "        lk.release()\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Func 2 says \", Loki)\n",
    "        time.sleep(random.random()/100) # засыпаем на случайный промежуток времени.\n",
    "            \n",
    "# создаем, а потом запускаем потоки.\n",
    "pr1=threading.Thread(target=func1)\n",
    "pr2=threading.Thread(target=func2)\n",
    "pr1.start()\n",
    "pr2.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Внимание!!!</b> Вызов двух блокировок подряд вызовет полную блокировку процесса, а также всех процессов, зависящих от данной блокировки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также для синхронизации работы потоков могут использоваться события и семафоры.\n",
    "\n",
    "Событие может быть установлено или сброшено. Если поток пытается установить установленное или сбросить сброшенное событие, он блокируется (но может быть разблокирован по тайм-ауту).\n",
    "\n",
    "Семафор фактически хранит информацию о нескольких событиях, то есть у семафора есть некоторый объем. Процесс блокируется при запросе ресурса из семафрра, только если тот уже был запрошен n раз и ресурс исчерпан.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 1\n",
      "read 1\n",
      "wrote 2\n",
      "read 2\n",
      "wrote 3\n",
      "read 3\n",
      "wrote 4\n",
      "read 4\n",
      "wrote 5\n",
      "read 5\n",
      "wrote 6\n",
      "read 6\n",
      "wrote 7\n",
      "read 7\n",
      "wrote 8\n",
      "read 8\n",
      "wrote 9\n",
      "read 9\n",
      "wrote 10\n",
      "read 10\n"
     ]
    }
   ],
   "source": [
    "# создадим очередь\n",
    "cntr = 0\n",
    "eve1 = threading.Event() # Разрешает читать читателю.\n",
    "eve2 = threading.Event() # Читатель прочитал, писатель может писать.\n",
    "\n",
    "# У нас будет два потока. \n",
    "# Writer будет писать даные в очередь через случайные промежутки времени. \n",
    "def writer():\n",
    "    global cntr\n",
    "    while cntr<10: #пишем 10 чисел\n",
    "        res = eve2.wait() # Всё прочитано, можно начинать писать.\n",
    "        eve2.clear() # Я понял, начинаю писать.\n",
    "        # Делаем какие-то долгие операции по генерации данных.\n",
    "        cntr+=1\n",
    "        print('wrote '+str(cntr)) # отчитываемся о записи.\n",
    "        eve1.set() # Данные готовы, можно читать.\n",
    "        time.sleep(random.random()) # засыпаем на случайный промежуток времени.\n",
    "\n",
    "# Reader в параллельном потоке читает из очереди через случайные промежутки времени.\n",
    "def reader():\n",
    "    while cntr<10: # пока прочитанное число меньше 10...\n",
    "        res = eve1.wait() # А не готовы ли данные для чтения?\n",
    "        if res:\n",
    "            print('read '+str(cntr)) # Отчитываемся.\n",
    "        else:\n",
    "            print('read failed')\n",
    "        eve1.clear() # Спасибо, я всё прочёл.\n",
    "        eve2.set() # Можно начинать писать.\n",
    "\n",
    "eve2.set() # Вначале писать может писать, а читателю нечего читать.\n",
    "eve1.clear()\n",
    "# создаем, а потом запускаем потоки.\n",
    "pr1=threading.Thread(target=writer)\n",
    "pr2=threading.Thread(target=reader)\n",
    "pr1.start()\n",
    "pr2.start()\n",
    "\n",
    "# Видно, как потоки работают параллельно, правда?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем организовать обмен данными при помощи `multiprocessing.queue`.\n",
    "Данный класс позволяет обмениваться информацией между потоками. При этом если поток-поставщик данных работает быстрее, то данные будут \"складироваться\" в очереди, пока потребитель их не заберет.\n",
    "Размер очереди может быть ограничен. В этом случае операция \"положить в очередь\" заблокирует поток, если очередь заполнена.\n",
    "Если очередь пуста, поток, запросивший данные также будет заблокирован при запросе данных. \n",
    "Для избежания блокировок можно использовать timeout (через какое время поток будет разблокирован и фцнкция сообщит о неуспехе).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 0\n",
      "read 0\n",
      "wrote 1\n",
      "read 1\n",
      "wrote 2\n",
      "read 2\n",
      "wrote 3\n",
      "read 3\n",
      "wrote 4\n",
      "read 4\n",
      "wrote 5\n",
      "read 5\n",
      "wrote 6\n",
      "read 6\n",
      "wrote 7\n",
      "read 7\n",
      "wrote 8\n",
      "wrote 9\n",
      "read 8\n",
      "read 9\n",
      "read 11\n"
     ]
    }
   ],
   "source": [
    "# создадим очередь\n",
    "cntr=0\n",
    "exch=multiprocessing.Queue(5)\n",
    "random.seed()\n",
    "\n",
    "# У нас будет два потока. \n",
    "# Writer будет писать даные в очередь через случайные промежутки времени. \n",
    "def writer():\n",
    "    global cntr\n",
    "    while cntr<10: #пишем 10 чисел\n",
    "        exch.put(cntr) # собственно пишем в очередь\n",
    "        print('wrote '+str(cntr)) # отчитываемся о записи.\n",
    "        cntr+=1\n",
    "        time.sleep(random.random()) # засыпаем на случайный промежуток времени.\n",
    "    exch.put(11) # конец данных.\n",
    "  \n",
    "# Reader в параллельном потоке читает из очереди через случайные промежутки времени.\n",
    "def reader():\n",
    "    i=-1\n",
    "    while i<10: # пока прочитанное число меньше 10...\n",
    "        i=exch.get() # Собственно читаем из очереди.\n",
    "        print('read '+str(i)) # Отчитываемся.\n",
    "        time.sleep(random.random()) # спим\n",
    "  \n",
    "# создаем, а потом запускаем потоки.\n",
    "pr1=multiprocessing.Process(target=writer)\n",
    "pr2=multiprocessing.Process(target=reader)\n",
    "pr1.start()\n",
    "pr2.start()\n",
    "\n",
    "# Видно, как потоки работают параллельно, правда?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем решить следующую задачу.\n",
    "\n",
    "Необходимо получать новости из нескольких источников. Далее каждая новость токенизируется в отдельном потоке, лемматизируется в еще одном потоке. В конце идет поток, который обрабатывает полученные данные.\n",
    "Новости также получаются в отдельных потоках.\n",
    "\n",
    "Для передачи данных используем очередь. \n",
    "\n",
    "Для сигнализации завершения работы потоков используем события и семафоры.\n",
    "\n",
    "Использование очереди, событий и семафоров позволяет синхронизировать операции в потоках. Токенизатор начнет разбор только после того, как очередь получит данные от одного из загрузчиков новостей. Результат будет помещен в другую очередь. Токенизатор \"уснет\" до тех пор, пока не придет еще одна новость, зато \"проснется\" лемматизатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!===--- ВНИМАНИЕ!!! ---===!!!\n",
    "# Код в данной ячейке работает некорректно, так как завершение процессов вызывает взаимную  блокировку!\n",
    "# Корректный вариант синхронизации показан ниже.\n",
    "\n",
    "\n",
    "# Функция для загрузки одной новости из Ленты.ру\n",
    "def getLentaArticle(url):\n",
    "    \"\"\" getLentaArticle gets the body of the article from Lenta.ru\"\"\"\n",
    "    r = requests.get(url)\n",
    "    body = re.findall('<div class=\"b-text clearfix js-topic__text\" itemprop=\"articleBody\"><p>(.+?)</p><div class=\"b-box\"><i>', r.text)\n",
    "    if len(body) > 0:\n",
    "        return BeautifulSoup(body[0], \"lxml\").get_text()\n",
    "    else:\n",
    "        return \"  \"\n",
    "\n",
    "# Функция загрузки одной новости из N+1.\n",
    "def getArticleTextNPlus1(adr):\n",
    "    r = requests.get(adr)\n",
    "    n_text = re.split(\"</div>\", re.split(\"</figure>\", re.split('</article>',re.split('<article', r.text)[1])[0])[1])[1]    \n",
    "    return BeautifulSoup(n_text, \"lxml\").get_text()\n",
    "\n",
    "# Загрузка новостей из Ленты.ру за некоторый период.\n",
    "def getLenta(qu, sem):\n",
    "    curdate = datetime.date(2017, 1, 16)\n",
    "    findate = datetime.date(2017, 1, 16)\n",
    "    res = \"\"\n",
    "\n",
    "# Загружаем новости до конечной даты.\n",
    "    while curdate <= findate:\n",
    "        print('lenta ' + curdate.strftime('%Y/%m/%d'))\n",
    "        day = requests.get('https://lenta.ru/news/' + curdate.strftime('%Y/%m/%d'))\n",
    "        body = re.findall('<h3>(.+?)</h3>', day.text)\n",
    "        links = ['https://lenta.ru' + re.findall('\"(.+?)\"', x)[0] for x in body]\n",
    "        for l in links: # идем по всем ссылкам на новости за день.\n",
    "            qu.put(getLentaArticle(l)) # Полученную новость кладем в очередь.\n",
    "            time.sleep(0.2)\n",
    "        curdate += datetime.timedelta(days=1)\n",
    "    sem.acquire() # Блокируем семафор один раз, по\n",
    "    print(\"lenta finished\")\n",
    "\n",
    "# Получаем новости с NPlus1 за заданный промежуток времени, кладем тексты новостей в очередь qu.\n",
    "# По завершении взводим семафор sem.\n",
    "def getNplus1(qu, sem):\n",
    "    curdate = datetime.date(2015, 12, 15)\n",
    "    findate = datetime.date(2015, 12, 19)\n",
    "\n",
    "    while curdate <= findate: # Перебираем все дни.\n",
    "        r = requests.get('https://nplus1.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "        print('nplus ' + curdate.strftime('%Y/%m/%d'))\n",
    "        # Берем заголовки и ссылки на новости за этот день.\n",
    "        refs = [re.split('\"', t)[6] for t in re.split('<article class=\"item item-news item-news', r.text)[1:]]\n",
    "        for t in refs:\n",
    "            qu.put(getArticleTextNPlus1(\"https://nplus1.ru\" + t)) # Получаем текст статьи и отправляем в очередь.\n",
    "            time.sleep(0.2) # Мы этичные хакеры и не стремимся к DDoS.\n",
    "        curdate += datetime.timedelta(days=1)\n",
    "    sem.acquire() # Взводим семафор.\n",
    "    print(\"nplus1 finished\")\n",
    "    \n",
    "# Функция токенизирует вход из очереди qu1 и кладет результаты токенизации в очередь qu2.\n",
    "# Токенизация ведется до тех пор, пока семафор semw не будет взведен максимальное количество раз.\n",
    "# По завершении токенизации устанавливаем событие evs.\n",
    "def tokenize(qu1, qu2, semw, evs):  \n",
    "    c = 0\n",
    "    # Пытаемся взвести семафор. Если не взведется, значит все потоки завершились (взведением семафора).\n",
    "    while semw.acquire(False): \n",
    "        txt = qu1.get() # Получаем данные из очереди.\n",
    "        semw.release() # Отпускаем семафор (мы же взвели его в while).\n",
    "        qu2.put(re.findall(\"[А-Яа-я]+(-[А-Яа-я]+)?\", txt)) # Очень простая токенизация кладет результаты в очередь.\n",
    "        c += 1\n",
    "        print('token '+str(c))\n",
    "    print(\"tokenization finished\")\n",
    "    evs.set() # Сообщаем о завершении работы установкой события.\n",
    "    print(\"tokenization finished\")\n",
    "\"\"\" Вот здесь-то и происходит блокировка.\n",
    "    while semw.acquire(False): блокирует семафор для потоков, поставляющих новости. В самом конце последний \n",
    "    поток с новостями заканчивает свою работу и пытается завершиться. Но семафор уже заполнен, и поток переводится\n",
    "    в состояние ожидания. При этом поток токенизации ждет получения данных txt=qu1.get(), но так как данные не \n",
    "    больше поступают, то он тоже блокируется. \n",
    "    Один поток ждет данных, чтобы продолжить работу и разблокировать семафор, другой заблокирован семафором и \n",
    "    больше не хочет отправлять данные. Клинч! Хорошо хоть, что в конце работы, но такое могло произойти и в середине.\n",
    "    \n",
    "    Через одну ячейку приведен код, который исправляет эту ситуацию.\n",
    "\"\"\"\n",
    "\n",
    "# Поток лемматизации текстов. Токены берутся из очереди qu1, результаты лемматизации кладутся в qu2.\n",
    "# Так как новости приходят по одной в токенизацию, скорее всего токены будут идти подряд. Но если вдруг у нас появится\n",
    "# еще один поток для токенизации, они начнут помещаться в очередь вперемешку. Так что такая технология подходит\n",
    "# только если нас не волнуется порядок слов.\n",
    "# Данный заканчиваются, когда будет установлено событие evw, сообщаем о своем завершении при помощи события evs.\n",
    "def lemmatize(qu1, qu2, evw, evs):\n",
    "    morpho = pymorphy2.MorphAnalyzer() # Создаем морфоанализатор.\n",
    "    l = []\n",
    "    c = 0\n",
    "    while not evw.is_set(): # Если событие установлено - пора завершать работу.\n",
    "        txt = qu1.get()\n",
    "        s = []\n",
    "        for w in txt:\n",
    "            s += morpho.parse(w)[0]\n",
    "        qu2.put(s) # Анализиируем, кладем результат в очередь.\n",
    "        c += 1\n",
    "        print('lemma ' + str(c))\n",
    "    evs.set() # ЗАвершаем работу.\n",
    "    print(\"lemmatization finished\")\n",
    "\n",
    "# Функция имитирует, что она обрабатывает данные из очереди qu. Заершает работу по событию ev.    \n",
    "def utilize(qu, ev):\n",
    "    c = 0\n",
    "    while not ev.is_set(): # Если событие установлено - пора завершать работу.\n",
    "        t = qu.get()\n",
    "        #processing\n",
    "        c += 1\n",
    "        print('process ' + str(c))\n",
    "    print('processing finished')\n",
    "\n",
    "# не надо тормозить при получении данных из очереди,\n",
    "# надо поставить ожидание если очередь пуста.\n",
    "# то, что есть - хороший пример на сложности синхронизации. еще очередь поменьше сделай.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenta 2017/01/16\n",
      "nplus 2015/12/15\n",
      "token 1\n",
      "token 2\n",
      "lemma 1\n",
      "token 3\n",
      "lemma 2\n",
      "lemma 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-6-e27d69e2da24>\", line 109, in utilize\n",
      "    t = qu.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pymorphy2/tagset.py\", line 279, in __init__\n",
      "    self._assert_grammemes_are_known(set(grammemes_tuple))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pymorphy2/tagset.py\", line 395, in _assert_grammemes_are_known\n",
      "    cls._assert_grammemes_initialized()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pymorphy2/tagset.py\", line 404, in _assert_grammemes_initialized\n",
      "    raise RuntimeError(msg)\n",
      "RuntimeError: The class was not properly initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 4\n",
      "lemma 4\n",
      "token 5\n",
      "lemma 5\n",
      "token 6\n",
      "lemma 6\n",
      "token 7\n",
      "lemma 7\n",
      "token 8\n",
      "lemma 8\n",
      "token 9\n",
      "lemma 9\n",
      "token 10\n",
      "token 11\n",
      "lemma 10\n",
      "lemma 11\n",
      "token 12\n",
      "lemma 12\n",
      "token 13\n",
      "lemma 13\n",
      "token 14\n",
      "lemma 14\n",
      "token 15\n",
      "lemma 15\n",
      "token 16\n",
      "lemma 16\n",
      "token 17\n",
      "lemma 17\n",
      "token 18\n",
      "lemma 18\n",
      "token 19\n",
      "lemma 19\n",
      "token 20\n",
      "lemma 20\n",
      "token 21\n",
      "token 22\n",
      "lemma 21\n",
      "lemma 22\n",
      "token 23\n",
      "lemma 23\n",
      "token 24\n",
      "lemma 24\n",
      "token 25\n",
      "lemma 25\n",
      "token 26\n",
      "lemma 26\n",
      "token 27\n",
      "lemma 27\n",
      "token 28\n",
      "lemma 28\n",
      "token 29\n",
      "lemma 29\n",
      "token 30\n",
      "lemma 30\n",
      "token 31\n",
      "lemma 31\n",
      "token 32\n",
      "lemma 32\n",
      "token 33\n",
      "lemma 33\n",
      "token 34\n",
      "lemma 34\n",
      "token 35\n",
      "lemma 35\n",
      "token 36\n",
      "lemma 36\n",
      "token 37\n",
      "lemma 37\n",
      "token 38\n",
      "lemma 38\n",
      "token 39\n",
      "lemma 39\n",
      "token 40\n",
      "lemma 40\n",
      "token 41\n",
      "lemma 41\n",
      "token 42\n",
      "lemma 42\n",
      "token 43\n",
      "lemma 43\n",
      "nplus 2015/12/16\n",
      "token 44\n",
      "lemma 44\n",
      "token 45\n",
      "lemma 45\n",
      "token 46\n",
      "lemma 46\n",
      "token 47\n",
      "lemma 47\n",
      "token 48\n",
      "lemma 48\n",
      "token 49\n",
      "lemma 49\n",
      "token 50\n",
      "lemma 50\n",
      "token 51\n",
      "lemma 51\n",
      "token 52\n",
      "lemma 52\n",
      "token 53\n",
      "lemma 53\n",
      "token 54\n",
      "token 55\n",
      "lemma 54\n",
      "lemma 55\n",
      "token 56\n",
      "lemma 56\n",
      "token 57\n",
      "lemma 57\n",
      "token 58\n",
      "token 59\n",
      "lemma 58\n",
      "lemma 59\n",
      "token 60\n",
      "lemma 60\n",
      "token 61\n",
      "lemma 61\n",
      "token 62\n",
      "lemma 62\n",
      "token 63\n",
      "lemma 63\n",
      "token 64\n",
      "lemma 64\n",
      "token 65\n",
      "lemma 65\n",
      "token 66\n",
      "lemma 66\n",
      "token 67\n",
      "lemma 67\n",
      "token 68\n",
      "lemma 68\n",
      "token 69\n",
      "lemma 69\n",
      "token 70\n",
      "lemma 70\n",
      "nplus 2015/12/17\n",
      "token 71\n",
      "lemma 71\n",
      "token 72\n",
      "lemma 72\n",
      "token 73\n",
      "lemma 73\n",
      "token 74\n",
      "lemma 74\n",
      "token 75\n",
      "lemma 75\n",
      "token 76\n",
      "lemma 76\n",
      "token 77\n",
      "lemma 77\n",
      "token 78\n",
      "lemma 78\n",
      "token 79\n",
      "lemma 79\n",
      "token 80\n",
      "lemma 80\n",
      "token 81\n",
      "lemma 81\n",
      "token 82\n",
      "lemma 82\n",
      "token 83\n",
      "lemma 83\n",
      "token 84\n",
      "lemma 84\n",
      "token 85\n",
      "lemma 85\n",
      "token 86\n",
      "lemma 86\n",
      "token 87\n",
      "lemma 87\n",
      "token 88\n",
      "lemma 88\n",
      "token 89\n",
      "lemma 89\n",
      "token 90\n",
      "lemma 90\n",
      "token 91\n",
      "lemma 91\n",
      "token 92\n",
      "lemma 92\n",
      "token 93\n",
      "lemma 93\n",
      "token 94\n",
      "lemma 94\n",
      "token 95\n",
      "lemma 95\n",
      "token 96\n",
      "lemma 96\n",
      "token 97\n",
      "lemma 97\n",
      "token 98\n",
      "lemma 98\n",
      "token 99\n",
      "lemma 99\n",
      "token 100\n",
      "lemma 100\n",
      "token 101\n",
      "lemma 101\n",
      "token 102\n",
      "token 103\n",
      "token 104\n",
      "token 105\n",
      "token 106\n",
      "nplus 2015/12/18\n",
      "token 107\n",
      "token 108\n",
      "token 109\n",
      "token 110\n",
      "token 111\n",
      "token 112\n",
      "token 113\n",
      "token 114\n",
      "token 115\n",
      "token 116\n",
      "token 117\n",
      "token 118\n",
      "token 119\n",
      "token 120\n",
      "token 121\n",
      "token 122\n",
      "token 123\n",
      "token 124\n",
      "token 125\n",
      "token 126\n",
      "token 127\n",
      "token 128\n",
      "token 129\n",
      "token 130\n",
      "token 131\n",
      "token 132\n",
      "token 133\n",
      "token 134\n",
      "token 135\n",
      "token 136\n",
      "token 137\n",
      "token 138\n",
      "token 139\n",
      "nplus 2015/12/19\n",
      "token 140\n",
      "token 141\n",
      "token 142\n",
      "token 143\n",
      "token 144\n",
      "token 145\n",
      "token 146\n",
      "token 147\n",
      "token 148\n",
      "token 149\n",
      "token 150\n",
      "token 151\n",
      "token 152\n",
      "token 153\n",
      "nplus1 finished\n",
      "token 154\n",
      "token 155\n",
      "token 156\n",
      "token 157\n",
      "token 158\n",
      "token 159\n",
      "token 160\n",
      "token 161\n",
      "token 162\n",
      "token 163\n",
      "token 164\n",
      "token 165\n",
      "token 166\n",
      "token 167\n",
      "token 168\n",
      "token 169\n",
      "token 170\n",
      "token 171\n",
      "token 172\n",
      "token 173\n",
      "token 174\n",
      "token 175\n",
      "token 176\n",
      "token 177\n",
      "token 178\n",
      "token 179\n",
      "token 180\n",
      "token 181\n",
      "token 182\n",
      "token 183\n",
      "token 184\n",
      "token 185\n",
      "token 186\n",
      "token 187\n",
      "token 188\n",
      "token 189\n",
      "token 190\n",
      "token 191\n",
      "token 192\n",
      "token 193\n",
      "token 194\n",
      "token 195\n",
      "token 196\n",
      "token 197\n",
      "token 198\n",
      "token 199\n",
      "token 200\n",
      "token 201\n",
      "token 202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-3:\n",
      "Process Process-5:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-6-e27d69e2da24>\", line 35, in getLenta\n",
      "    qu.put(getLentaArticle(l)) # Полученную новость кладем в очередь.\n",
      "  File \"<ipython-input-6-e27d69e2da24>\", line 68, in tokenize\n",
      "    qu2.put(re.findall(\"[А-Яа-я]+(-[А-Яа-я]+)?\", txt)) # ОЧень простая токенизация кладет результаты в очередь.\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-6-e27d69e2da24>\", line 99, in lemmatize\n",
      "    qu2.put(s) # Анализиируем, кладем результат в очередь.\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 322, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 191, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 1056, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Два потока новостей.\n",
    "newswirenumber = 2\n",
    "\n",
    "# Создаем очереди, семафор и события для синхронизации.\n",
    "textsq = multiprocessing.Queue(100)\n",
    "tokenq = multiprocessing.Queue(100)\n",
    "lemmaq = multiprocessing.Queue(100)\n",
    "newss = multiprocessing.Semaphore(newswirenumber)\n",
    "tokene = multiprocessing.Event()\n",
    "lemmae = multiprocessing.Event()\n",
    "\n",
    "# Запускаем процессы.\n",
    "lentap = multiprocessing.Process(target=getLenta, args=(textsq, newss,))\n",
    "nplusp = multiprocessing.Process(target=getNplus1, args=(textsq, newss,))  \n",
    "tokenp = multiprocessing.Process(target=tokenize, args=(textsq, tokenq, newss, tokene, ))   \n",
    "lemmap = multiprocessing.Process(target=lemmatize, args=(tokenq, lemmaq, tokene, lemmae, ))   \n",
    "processp = multiprocessing.Process(target=utilize, args=(lemmaq, lemmae, ))    \n",
    "    \n",
    "# Стартуем процессы    \n",
    "lentap.start()\n",
    "nplusp.start()\n",
    "tokenp.start()\n",
    "lemmap.start()\n",
    "processp.start()\n",
    "\n",
    "# Если надо - ждем пока процессы не завершатся.\n",
    "#lentap.join()\n",
    "#nplusp.join()\n",
    "#tokenp.join()\n",
    "#lemmap.join()\n",
    "#processp.join()\n",
    "#print(\"Everything is allright\")                               \n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Это код работает более корректно, чем тот, что приведен выше.\n",
    "# Большая часть комментариев опущена, оставлены только те, что помогают понять изменения в логике.\n",
    "\n",
    "def getLentaArticle(url):\n",
    "    # Вместо того, что вызывать Ктулху тем, что мы разбираем XML при помощи регулярок,\n",
    "    # давайте будем использовать мощь BeautifulSoup.\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    beau = BeautifulSoup(r.text, \"lxml\")\n",
    "    beau_text = beau(\"p\") # Найди-ка мне все фрагменты, отмеченные как параграф.\n",
    "        \n",
    "    if len(beau_text) > 0:\n",
    "        return \"\\n\".join([b.get_text() for b in beau_text])\n",
    "    else:\n",
    "        return \"  \"\n",
    "\n",
    "def getArticleTextNPlus1(adr):\n",
    "    r = requests.get(adr)\n",
    "    n_text = re.split(\"</div>\", re.split(\"</figure>\", re.split('</article>',re.split('<article', r.text)[1])[0])[1])[1]    \n",
    "    return BeautifulSoup(n_text, \"lxml\").get_text()\n",
    "\n",
    "def getLenta(qu, sem):\n",
    "    curdate = datetime.date(2017, 1, 16)\n",
    "    findate = datetime.date(2017, 1, 16)\n",
    "    res=\"\"\n",
    "\n",
    "    while curdate <= findate:\n",
    "        print('lenta ' + curdate.strftime('%Y/%m/%d'))\n",
    "        day = requests.get('https://lenta.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "        body = re.findall('<h3>(.+?)</h3>', day.text)\n",
    "        links = ['https://lenta.ru'+re.findall('\"(.+?)\"', x)[0] for x in body]\n",
    "        for l in links[:50]:\n",
    "            qu.put(getLentaArticle(l))\n",
    "            time.sleep(0.2)\n",
    "        curdate += datetime.timedelta(days=1)\n",
    "    sem.acquire()\n",
    "    print(\"lenta finished\")\n",
    "\n",
    "def getNplus1(qu, sem):\n",
    "    curdate = datetime.date(2015, 12, 15)\n",
    "    findate = datetime.date(2015, 12, 18)\n",
    "\n",
    "    while curdate <= findate:\n",
    "        r = requests.get('https://nplus1.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "        print('nplus ' + curdate.strftime('%Y/%m/%d'))\n",
    "        refs=[re.split('\"', t)[6] for t in re.split('<article class=\"item item-news item-news', r.text)[1:]]\n",
    "        for t in refs:\n",
    "            qu.put(getArticleTextNPlus1(\"https://nplus1.ru\"+t))\n",
    "            time.sleep(0.2)\n",
    "        curdate += datetime.timedelta(days=1)\n",
    "    sem.acquire()\n",
    "    print(\"nplus1 finished\")\n",
    "    \n",
    "# На входе - те же самые очереди, семафор и событие, но используем мы их по-другому.\n",
    "def tokenize(qu1, qu2, semw, evs):  \n",
    "    c = 0\n",
    "    while semw.acquire(False): # Так же пытаемся получить семафор.\n",
    "        try:\n",
    "            semw.release() # ! Первым делом отпускаем его, чтобы никого не держать больше.\n",
    "            txt = qu1.get(timeout=0.1) # Если что-то пойдет не так, нас отпустят через 0,1 секунды.\n",
    "        except queue.Empty: # Если произршел выход по таймауту, генерируется исключение.\n",
    "            #print('tokenization waits')\n",
    "            pass # Данных нет, пойдем посмотрим, может вообще завершаться пора?\n",
    "        else:\n",
    "            qu2.put(re.findall(\"[А-Яа-я]+(-[А-Яа-я]+)?\", txt)) # Данные есть - токенизируем и кладем в очередь.\n",
    "            c += 1\n",
    "            print('token '+str(c))\n",
    "\n",
    "    print(\"tokenization \")\n",
    "    evs.set()\n",
    "    print(\"finished\")\n",
    "\n",
    "def lemmatize(qu1, qu2, evw, evs):\n",
    "    morpho = pymorphy2.MorphAnalyzer()\n",
    "    l = []\n",
    "    c = 0\n",
    "    while not evw.is_set():\n",
    "        try:\n",
    "            txt = qu1.get(timeout=0.1) # Поддерживаем логику таймаута везде на всякий случай.\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        else:\n",
    "            s = []\n",
    "            for w in s:\n",
    "                s += morpho.parse(w)[0]\n",
    "            qu2.put(s)\n",
    "            c += 1\n",
    "            print('lemma '+str(c))\n",
    "    evs.set()\n",
    "    print(\"lemmatization finished\")\n",
    "\n",
    "def utilize(qu, ev):\n",
    "    c = 0\n",
    "    while not ev.is_set(): # Поддерживаем логику таймаута везде на всякий случай.\n",
    "        try:\n",
    "            t = qu.get(timeout=0.1)\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        else:\n",
    "        #processing\n",
    "            c += 1\n",
    "            print('process '+str(c))\n",
    "    print('processing finished')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
